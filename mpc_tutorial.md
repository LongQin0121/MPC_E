https://towardsdatascience.com/model-predictive-control-basics/

https://github.com/willem-daniel-esterhuizen/MPC_tutorial

# Model Predictive Control Basics
## A hands-on tutorial with Python and CasADi
Willem Esterhuizen

## Quick Summary
In this article we will:

Cover the basic ideas.
Code up a solver in Python.
Play with a simple linear system: the double integrator.
Get all the code here: https://github.com/willem-daniel-esterhuizen/MPC_tutorial

## 1. Introduction
Model predictive control (MPC) is a popular feedback control methodology where a finite-horizon optimal control problem (OCP) is iteratively solved with an updated measured state on each iteration.

![alt text](90b4edb2-a313-4dd4-81e6-659f226dc7f4.png)

In the OCP one uses a model of the plant to find the optimal open loop control over the finite horizon considered. Because the model cannot capture the true plantâ€™s behaviour 100%, and because in the real world the system is subjected to noise and disturbances, one only applies the first portion of the optimal open loop control, and regularly measures the state to re-solve the OCP. This closes the loop and creates a feedback.

The maths behind it is relatively simple and intuitive (especially when compared to things like robust control) and it is easy to code up an MPC controller. Other pros are that it can effectively handle hard and soft constraints on the state and control (hard constraints are strict, whereas soft constraints are enforced via penalisation in the cost function) and it can generally be used on nonlinear systems with nonconvex constraints (depending on how nasty these are of course!). The only con is that you need to solve a optimization problems â€œonlineâ€ in real time, which can be a problem if youâ€™re controlling a fast system or have limited computing resources.

### 1.2 Running Example
Throughout the article I will consider the double integrator with a zero-order hold control (i.e. a piecewise constant control) as the running example in the code. The continuous time system reads:
\[
\begin{align*}
\dot{x}_1(t) &= x_2(t), \\
\dot{x}_2(t) &= u(t),
\end{align*}
\]
With \( t \in \mathbb{R} \) denoting time. Here \( x_1(t) \in \mathbb{R} \) is the position whereas \( x_2(t) \in \mathbb{R} \) is the velocity. You can think of this system as a 1kg block sliding on a frictionless table, with \( u(t) \) the applied force.

![alt text](62c0b31c-fd11-4028-ab5f-3113a61bb424.png)

If we constrain the control to be piecewise constant over intervals of length 0.1 seconds, we get the discrete-time system:

\[ x_{k+1} = Ax_k + Bu_k, \]

with \( k \in \mathbb{Z} \), where,

\[ 
A := \begin{pmatrix} 
1 & 0.1 \\ 
0 & 1 
\end{pmatrix}, \quad 
B := \begin{pmatrix} 
0.05 \\ 
1 
\end{pmatrix} 
\]

and \( x_k \in \mathbb{R}^2 \), \( u_k \in \mathbb{R} \).

(Note that I use \( x_k \) and \( u_k \) to refer to the discrete-time systemâ€™s state and control to make the notation neater in the rest of the article.)

## AçŸ©é˜µï¼š

\[ 
A = \begin{pmatrix} 
1 & 0.1 \\ 
0 & 1 
\end{pmatrix} 
\]

- ç¬¬1è¡Œï¼šä½ç½®çš„çŠ¶æ€è½¬ç§»æ–¹ç¨‹
- ç¬¬2è¡Œï¼šé€Ÿåº¦çš„çŠ¶æ€è½¬ç§»æ–¹ç¨‹

## BçŸ©é˜µï¼š

\[ 
B = \begin{pmatrix} 
0.005 \\ 
0.1 
\end{pmatrix} 
\]

- ç¬¬1è¡Œï¼šæ§åˆ¶è¾“å…¥å¯¹ä½ç½®çš„å½±å“
- ç¬¬2è¡Œï¼šæ§åˆ¶è¾“å…¥å¯¹é€Ÿåº¦çš„å½±å“

## å®Œæ•´çš„ç¦»æ•£ç³»ç»Ÿæ–¹ç¨‹ï¼š

[xâ‚(k+1)]   [1   0.1] [xâ‚(k)]   [0.005]
[xâ‚‚(k+1)] = [0   1  ] [xâ‚‚(k)] + [0.1  ] u(k)

## å±•å¼€å°±æ˜¯ï¼š

- ä½ç½®æ–¹ç¨‹ï¼š\( xâ‚(k+1) = xâ‚(k) + 0.1 \cdot xâ‚‚(k) + 0.005 \cdot u(k) \)
- é€Ÿåº¦æ–¹ç¨‹ï¼š\( xâ‚‚(k+1) = xâ‚‚(k) + 0.1 \cdot u(k) \)


You can use the scipy packagesâ€™s cont2discrete function to get this discrete time system, as follows:

```python
import numpy as np
from scipy.signal import cont2discrete

A = np.array([[0, 1],[0, 0]])
B = np.array([[0],[1]])
C = np.array([[1, 0],[0, 1]])
D = np.array([[0, 0],[0, 0]])
dt = 0.1 # in seconds
discrete_system = cont2discrete((A, B, C, D), dt, method='zoh')
A_discrete, B_discrete, *_ = discrete_system

```
scipyçš„cont2discreteå‡½æ•°ä¼˜åŠ¿

è‡ªåŠ¨åŒ–è®¡ç®— - ä¸éœ€è¦æ‰‹å·¥æ¨å¯¼çŸ©é˜µæŒ‡æ•°å’Œç§¯åˆ†
æ•°å€¼ç¨³å®š - ä½¿ç”¨é«˜ç²¾åº¦ç®—æ³•
æ”¯æŒå¤šç§æ–¹æ³• - zohï¼ˆé›¶é˜¶ä¿æŒï¼‰ã€fohï¼ˆä¸€é˜¶ä¿æŒï¼‰ç­‰
é¿å…è®¡ç®—é”™è¯¯ - ç‰¹åˆ«æ˜¯å¯¹äºé«˜ç»´å¤æ‚ç³»ç»Ÿ

æ‰€ä»¥å½“ä½ é¢å¯¹æ–°çš„ç³»ç»Ÿæ—¶ï¼Œåªéœ€è¦ï¼š

å»ºç«‹è¿ç»­æ—¶é—´æ¨¡å‹ï¼ˆA, B, C, DçŸ©é˜µï¼‰
é€‰æ‹©é‡‡æ ·æ—¶é—´ï¼ˆdtï¼‰
è°ƒç”¨scipyå‡½æ•°è‡ªåŠ¨ç¦»æ•£åŒ–

åŸå§‹å¾®åˆ†æ–¹ç¨‹ï¼š
áº‹â‚(t) = xâ‚‚(t)
áº‹â‚‚(t) = u(t)
å†™æˆçŸ©é˜µå½¢å¼ï¼š
[áº‹â‚(t)]   [0 1] [xâ‚(t)]   [0]
[áº‹â‚‚(t)] = [0 0] [xâ‚‚(t)] + [1] u(t)
æ‰€ä»¥ï¼šA = [[0,1],[0,0]], B = [[0],[1]]
è¾“å‡ºæ–¹ç¨‹ï¼š
å‡è®¾æˆ‘ä»¬æƒ³è§‚æµ‹ä½ç½®å’Œé€Ÿåº¦ï¼š
[yâ‚(t)]   [1 0] [xâ‚(t)]   [0]
[yâ‚‚(t)] = [0 1] [xâ‚‚(t)] + [0] u(t)
æ‰€ä»¥ï¼šC = [[1,0],[0,1]]ï¼ˆå•ä½çŸ©é˜µï¼‰ï¼ŒD = [[0],[0]]ï¼ˆé€šå¸¸ä¸ºé›¶ï¼‰
æ€»ç»“
ABCDçŸ©é˜µå°±æ˜¯ä»åŸå§‹çš„ç‰©ç†å¾®åˆ†æ–¹ç¨‹ç›´æ¥å†™å‡ºæ¥çš„ï¼
ç‰©ç†æ–¹ç¨‹ â†’ çŠ¶æ€ç©ºé—´å½¢å¼ â†’ A,B,C,DçŸ©é˜µ

## 2. Optimal Control Problem

1. è¿è¡Œæˆæœ¬ï¼ˆRunning Costï¼‰
çŠ¶æ€æˆæœ¬ï¼šx_k^T Q x_k
x_k^T Q x_k = [xâ‚â‚– xâ‚‚â‚–] [qâ‚â‚ qâ‚â‚‚] [xâ‚â‚–]
                          [qâ‚â‚‚ qâ‚‚â‚‚] [xâ‚‚â‚–]
              = qâ‚â‚xâ‚â‚–Â² + 2qâ‚â‚‚xâ‚â‚–xâ‚‚â‚– + qâ‚‚â‚‚xâ‚‚â‚–Â²
ç‰©ç†å«ä¹‰ï¼š

qâ‚â‚ï¼šä½ç½®åå·®çš„æƒ©ç½šæƒé‡
qâ‚‚â‚‚ï¼šé€Ÿåº¦åå·®çš„æƒ©ç½šæƒé‡
qâ‚â‚‚ï¼šä½ç½®-é€Ÿåº¦äº¤å‰é¡¹ï¼ˆé€šå¸¸ä¸º0ï¼‰

æ§åˆ¶æˆæœ¬ï¼šu_k^T R u_k = RÂ·u_kÂ²
ç‰©ç†å«ä¹‰ï¼š

æƒ©ç½šæ§åˆ¶åŠ›çš„ä½¿ç”¨
Rè¶Šå¤§ â†’ è¶Š"èŠ‚èƒ½"ï¼Œæ§åˆ¶è¶Šæ¸©å’Œ
Rè¶Šå° â†’ æ§åˆ¶è¶Š"æ¿€è¿›"

2. ç»ˆç«¯æˆæœ¬ï¼ˆTerminal Costï¼‰
x_K^T Q_K x_K
ç‰©ç†å«ä¹‰ï¼š

ç¡®ä¿æœ€ç»ˆçŠ¶æ€æ¥è¿‘æœŸæœ›å€¼
é€šå¸¸ Q_K >> Qï¼ˆç»ˆç«¯æƒ©ç½šæ›´é‡ï¼‰
ä¿è¯ç³»ç»Ÿæœ€ç»ˆ"åœåœ¨æ­£ç¡®ä½ç½®"

3. è®¾è®¡æƒè¡¡
å…¸å‹æƒé‡é€‰æ‹©ï¼š
pythonQ = [[10,  0 ],    # ä½ç½®å¾ˆé‡è¦
     [0,   1 ]]    # é€Ÿåº¦è¾ƒæ¬¡è¦

R = 0.1            # æ§åˆ¶æˆæœ¬è¾ƒå°

Q_K = [[100, 0 ],  # ç»ˆç«¯ä½ç½®éå¸¸é‡è¦  
       [0,   10]]  # ç»ˆç«¯é€Ÿåº¦ä¹Ÿé‡è¦
æƒé‡å½±å“ï¼š

å¤§Q â†’ çŠ¶æ€è·Ÿè¸ªç²¾ç¡®ï¼Œä½†å¯èƒ½æ§åˆ¶æ¿€çƒˆ
å¤§R â†’ æ§åˆ¶å¹³æ»‘ï¼Œä½†è·Ÿè¸ªå¯èƒ½è¾ƒå·®
å¤§Q_K â†’ ç»ˆç«¯ç²¾åº¦é«˜ï¼Œä½†è¿‡ç¨‹å¯èƒ½ä¸å¹³ç¨³

4. ç‰©ç†ç›´è§‰
è¿™ä¸ªä»£ä»·å‡½æ•°åœ¨è¯´ï¼š

"æˆ‘å¸Œæœ›ç³»ç»ŸçŠ¶æ€å°½é‡å°ï¼ˆæ¥è¿‘åŸç‚¹ï¼‰ï¼Œæ§åˆ¶åŠ›å°½é‡å°ï¼Œæœ€ç»ˆçŠ¶æ€ç‰¹åˆ«è¦å°"

è¿™å°±æ˜¯å…¸å‹çš„è°ƒèŠ‚å™¨é—®é¢˜ï¼šæŠŠç³»ç»Ÿç¨³å®šåˆ°åŸç‚¹ï¼
Weâ€™ll consider the following discrete-time optimal control problem (OCP):
## Optimal Control Problem

We consider the following Optimal Control Problem (OCP):

\[
\begin{aligned}
& \min_{u, x} && \sum_{k=0}^{K-1} \left( x_k^\top Q x_k + u_k^\top R u_k \right) + x_K^\top Q_K x_K \\
& \text{subject to:} \\
& && x_{k+1} = A x_k + B u_k, \quad x_0 = \bar{x}, \\
& && x_k \in [-1, 1] \times (-\infty, \infty), \\
& && u_k \in [-1, 1], \\
& && k \in [0:K-1], \\
& && k \in [1:K], \\
& && k \in [0:K-1], \dots
\end{aligned}
\]

### Where:

- \( K \in \mathbb{R}_{\geq 0} \) denotes the finite horizon over which we solve the OCP.
- \( k \in \mathbb{Z} \) denotes the discrete time step.
- \([p:q]\), with \( p, q \in \mathbb{Z} \), denotes the set of integers \(\{ p, p+1, \ldots, q \}\).
- \(\bar{x} \in \mathbb{R}^2\) denotes the initial condition of the dynamical system.
- \(x_k \in \mathbb{R}^2\) denotes the state at step \(k\).
- \(u_k \in \mathbb{R}\) denotes the control at step \(k\).
- \( Q \in \mathbb{R}^{2 \times 2}, R \in \mathbb{R}, \text{ and } Q_K \in \mathbb{R}^{2 \times 2} \) are square positive definite matrices that specify the cost function (R is scalar here because \( u \) is scalar).

### Additional Notations:

- \( u = (u_0, u_1, \ldots, u_{K-1}) \in \mathbb{R}^K \) denotes the control sequence.
- \( x = (x_0, x_1, \ldots, x_K) \in \mathbb{R}^{2(K+1)} \) denotes the state sequence.

## Optimal Control Problem (OCP)

To be rigorous, weâ€™ll say that the pair \((u^*, x^*) \in \mathbb{R}^K \times \mathbb{R}^{2(K+1)}\) is a solution to \(\text{OCP}(\bar{x})\) provided that it minimizes the cost function over all admissible pairs, that is,

\[
J(u^*, x^*) \leq J(u, x), \quad \forall (u, x) \in \Omega
\]

where \(J: \mathbb{R}^K \times \mathbb{R}^{2(K+1)} \to \mathbb{R}_{\geq 0}\) is defined as,

\[
J(u, x) = \left( \sum_{k=0}^{K-1} x_k^\top Q x_k + u_k^\top R u_k \right) + x_K^\top Q_K x_K
\]

and \(\Omega\) denotes all admissible pairs:

\[
\Omega = \{ (u, x) \in \mathbb{R}^K \times \mathbb{R}^{2(K+1)} : \text{conditions (1)âˆ’(4) hold} \}.
\]

Thus, the optimal control problem is to find a control and state sequence, \((u^*, x^*)\), that minimizes the cost function, subject to the dynamics, \(f\), as well as constraints on the state and control: \(x_k \in [-1, 1] \times (-\infty, \infty)\), \(u_k \in [-1, 1]\), for all \(k\). The cost function is vital to the controllerâ€™s performance. Not only in the sense of ensuring the controller behaves well (for example, to prevent erratic signals) but also in specifying the equilibrium point the closed loop state will settle at. More on this in Section 4.

Note how \(\text{OCP}(\bar{x})\) is parameterized with respect to the initial state, \(\bar{x}\). This comes from the fundamental idea behind Model Predictive Control (MPC): that the optimal control problem is iteratively solved with an updated measured state.

è¿™æ®µè¯çš„æ ¸å¿ƒä¿¡æ¯ï¼š

ä¸¥æ ¼å®šä¹‰äº†ä»€ä¹ˆå«"è§£å†³"æœ€ä¼˜æ§åˆ¶é—®é¢˜ï¼š

æ‰¾åˆ°ä¸€å¯¹æ§åˆ¶å’ŒçŠ¶æ€åºåˆ— (u*, x*)
è¿™å¯¹åºåˆ—å¿…é¡»æ»¡è¶³æ‰€æœ‰çº¦æŸæ¡ä»¶
åœ¨æ‰€æœ‰æ»¡è¶³çº¦æŸçš„åºåˆ—ä¸­ï¼Œå®ƒçš„æˆæœ¬æœ€å°
è¿™å°±æ˜¯æˆ‘ä»¬è¦çš„"æœ€ä¼˜è§£"


ç®€å•æ€»ç»“ï¼šåœ¨æ‰€æœ‰"å¯ä»¥åšçš„"æ–¹æ¡ˆä¸­ï¼Œæ‰¾åˆ°"æœ€å¥½çš„"é‚£ä¸€ä¸ªï¼
u_k^T R u_k é¡¹çš„ä½œç”¨ï¼š
- R å¾ˆå¤§ â†’ æƒ©ç½šå¤§çš„æ§åˆ¶è¾“å…¥ â†’ å¹³æ»‘æ§åˆ¶
- R å¾ˆå° â†’ å…è®¸å¤§çš„æ§åˆ¶è¾“å…¥ â†’ å¯èƒ½å‰§çƒˆå˜åŒ–
å®é™…ä¾‹å­ï¼š

æ±½è½¦æ§åˆ¶ï¼šé˜²æ­¢æ–¹å‘ç›˜æ€¥è½¬ã€æ€¥åŠ é€Ÿæ€¥åˆ¹è½¦
æœºå™¨äººï¼šé˜²æ­¢å…³èŠ‚è¿åŠ¨è¿‡äºå‰§çƒˆ
åŒ–å·¥è¿‡ç¨‹ï¼šé˜²æ­¢é˜€é—¨é¢‘ç¹å¼€å…³

## 2.1 Coding an OCP solver
CasADiâ€™s opti stack makes it really easy to set up and solve the OCP.

First, some preliminaries:
```python
from casadi import *

n = 2 # state dimension
m = 1 # control dimension
K = 100 # prediction horizon

# an arbitrary initial state
x_bar = np.array([[0.5],[0.5]]) # 2 x 1 vector

# Linear cost matrices (we'll just use identities)
Q = np.array([[1. , 0],
            [0. , 1. ]])
R = np.array([[1]])
Q_K = Q

# Constraints for all k
u_max = 1
x_1_max = 1
x_1_min = -1

```

Now we define the problemâ€™s decision variables:
```python
opti = Opti()

x_tot = opti.variable(n, K+1)  # State trajectory
u_tot = opti.variable(m, K)    # Control trajectory
```
optiï¼šä¼˜åŒ–é—®é¢˜çš„å®¹å™¨
x_totï¼šåŒ…å«æ•´ä¸ªé¢„æµ‹æ—¶åŸŸçš„çŠ¶æ€åºåˆ—
u_totï¼šåŒ…å«æ•´ä¸ªé¢„æµ‹æ—¶åŸŸçš„æ§åˆ¶åºåˆ—
ç»´åº¦åŒ¹é…ï¼šçŠ¶æ€æ¯”æ§åˆ¶å¤šä¸€ä¸ªæ—¶é—´ç‚¹ï¼ˆå› ä¸ºåŒ…å«ç»ˆç«¯çŠ¶æ€ï¼‰
m=2, n=1  ç»´åº¦

Next, we impose the dynamic constraints and set up the cost function:
```python
# Specify the initial condition
opti.subject_to(x_tot[:, 0] == x_bar)

cost = 0
for k in range(K):
    # add dynamic constraints
    x_tot_next = get_x_next_linear(x_tot[:, k], u_tot[:, k])
    opti.subject_to(x_tot[:, k+1] == x_tot_next)

    # add to the cost
    cost += mtimes([x_tot[:,k].T, Q, x_tot[:,k]]) + \     
                           mtimes([u_tot[:,k].T, R, u_tot[:,k]])

# terminal cost
cost += mtimes([x_tot[:,K].T, Q_K, x_tot[:,K]])

```


```python
def get_x_next_linear(x, u):
    # Linear system
    A = np.array([[1. , 0.1],
                [0. , 1. ]])
    B = np.array([[0.005],
                  [0.1  ]])
    
    return mtimes(A, x) + mtimes(B, u)

```

x_tot[:,k]     # ç¬¬kæ—¶åˆ»çš„çŠ¶æ€å‘é‡ x_k (2Ã—1)
x_tot[:,k].T   # è½¬ç½®åçš„è¡Œå‘é‡ x_k^T (1Ã—2)  
Q              # æƒé‡çŸ©é˜µ (2Ã—2)
x_tot[:,k]     # å†æ¬¡ä½¿ç”¨çŠ¶æ€å‘é‡ x_k (2Ã—1)

mtimes([x_tot[:,k].T, Q, x_tot[:,k]])
#       â†‘            â†‘   â†‘
#      (1Ã—2)       (2Ã—2) (2Ã—1)
#         â†˜       â†™      â†“
#         (1Ã—2)          â†“
#           â†˜           â†™
#            (1Ã—1) = æ ‡é‡


ç³»ç»ŸåŠ¨åŠ›å­¦ vs æˆæœ¬å‡½æ•° æ˜¯ä¸¤å›äº‹ï¼
çº¿æ€§çš„éƒ¨åˆ†ï¼šç³»ç»ŸåŠ¨åŠ›å­¦
pythondef get_x_next_linear(x, u):
    # è¿™é‡Œæ˜¯"çº¿æ€§"çš„ï¼
    return A @ x + B @ u  # x_{k+1} = Ax_k + Bu_k
è¿™æ˜¯çº¿æ€§çš„ï¼š

çŠ¶æ€è½¬ç§»æ–¹ç¨‹æ˜¯çº¿æ€§çš„
æ²¡æœ‰ x2x^2
x2ã€sinâ¡(x)\sin(x)
sin(x) ç­‰éçº¿æ€§é¡¹


äºŒæ¬¡çš„éƒ¨åˆ†ï¼šæˆæœ¬å‡½æ•°
python# è¿™é‡Œæ˜¯"äºŒæ¬¡"çš„ï¼
cost += mtimes([x_tot[:,k].T, Q, x_tot[:,k]])  # x_k^T Q x_k
è¿™æ˜¯äºŒæ¬¡å‹ï¼š

æˆæœ¬å‡½æ•°åŒ…å«çŠ¶æ€çš„å¹³æ–¹é¡¹
ç›®çš„æ˜¯æƒ©ç½šåç¦»åŸç‚¹çš„ç¨‹åº¦

ä¸¤è€…çš„åŒºåˆ«å’Œè”ç³»
1. åŠ¨åŠ›å­¦çº¦æŸï¼ˆçº¿æ€§ï¼‰
python# æè¿°ç³»ç»Ÿå¦‚ä½•æ¼”åŒ–
x_{k+1} = Ax_k + Bu_k  # çº¿æ€§å…³ç³»
ç‰©ç†å«ä¹‰ï¼š

å‘Šè¯‰æˆ‘ä»¬"ç»™å®šå½“å‰çŠ¶æ€å’Œæ§åˆ¶ï¼Œä¸‹ä¸€çŠ¶æ€æ˜¯ä»€ä¹ˆ"
è¿™æ˜¯ç‰©ç†å®šå¾‹ï¼Œå¿…é¡»æ»¡è¶³

2. æˆæœ¬å‡½æ•°ï¼ˆäºŒæ¬¡ï¼‰
python# æè¿°æˆ‘ä»¬çš„åå¥½
J = Î£(x_k^T Q x_k + u_k^T R u_k)  # äºŒæ¬¡å‹
è®¾è®¡å«ä¹‰ï¼š

å‘Šè¯‰æˆ‘ä»¬"ä»€ä¹ˆæ ·çš„çŠ¶æ€å’Œæ§åˆ¶æ˜¯å¥½çš„"
è¿™æ˜¯äººä¸ºè®¾è®¡çš„ï¼Œå¯ä»¥é€‰æ‹©

ä¸ºä»€ä¹ˆä¼šè¿™æ ·è®¾è®¡ï¼Ÿ
åŠ¨åŠ›å­¦é€‰æ‹©çº¿æ€§çš„åŸå› 
python# 1. ç‰©ç†ç³»ç»Ÿæœ¬èº«å¯èƒ½æ˜¯çº¿æ€§çš„ï¼ˆå¦‚è´¨ç‚¹è¿åŠ¨ï¼‰
# 2. éçº¿æ€§ç³»ç»Ÿçš„çº¿æ€§åŒ–è¿‘ä¼¼
# 3. è®¡ç®—ç®€å•ï¼Œé€‚åˆå®æ—¶æ§åˆ¶
æˆæœ¬é€‰æ‹©äºŒæ¬¡çš„åŸå› 
python# 1. æ•°å­¦æ€§è´¨å¥½ï¼ˆå‡¸å‡½æ•°ï¼‰
# 2. å¤§åå·®æƒ©ç½šé‡ï¼Œå°åå·®å®¹å¿
# 3. æœ‰è§£æè§£ï¼ˆLQRï¼‰
# 4. è®¡ç®—é«˜æ•ˆï¼ˆäºŒæ¬¡è§„åˆ’ï¼‰
å®Œæ•´çš„MPCé—®é¢˜ç»“æ„
pythonminimize    Î£(x_k^T Q x_k + u_k^T R u_k)    # â† äºŒæ¬¡ç›®æ ‡å‡½æ•°
subject to  x_{k+1} = Ax_k + Bu_k            # â† çº¿æ€§åŠ¨åŠ›å­¦çº¦æŸ
            u_k âˆˆ [-1, 1]                    # â† çº¿æ€§ä¸ç­‰å¼çº¦æŸ
            x_k âˆˆ feasible_set               # â† çº¿æ€§ä¸ç­‰å¼çº¦æŸ
é—®é¢˜ç±»å‹ï¼šçº¿æ€§çº¦æŸçš„äºŒæ¬¡è§„åˆ’ï¼ˆLinear-Quadratic Programmingï¼‰
ç±»æ¯”ç†è§£
ç±»æ¯”ï¼šå¼€è½¦å¯¼èˆª
åŠ¨åŠ›å­¦ï¼ˆçº¿æ€§ï¼‰ï¼š
"è½¦è¾†å¦‚ä½•è¿åŠ¨"
é€Ÿåº¦[k+1] = é€Ÿåº¦[k] + åŠ é€Ÿåº¦[k] * æ—¶é—´
ä½ç½®[k+1] = ä½ç½®[k] + é€Ÿåº¦[k] * æ—¶é—´

è¿™æ˜¯ç‰©ç†å®šå¾‹ï¼Œä¸èƒ½è¿åï¼
æˆæœ¬å‡½æ•°ï¼ˆäºŒæ¬¡ï¼‰ï¼š
"ä»€ä¹ˆæ ·çš„é©¾é©¶æ˜¯å¥½çš„"
æˆæœ¬ = (åç¦»è½¦é“è·ç¦»)Â² + (è¶…é€Ÿç¨‹åº¦)Â² + (æ€¥åŠ é€Ÿç¨‹åº¦)Â²

è¿™æ˜¯åå¥½è®¾è®¡ï¼Œå¯ä»¥è°ƒæ•´ï¼
æ•°å­¦ä¸Šçš„å…¼å®¹æ€§
ä¸ºä»€ä¹ˆå¯ä»¥ç»“åˆï¼Ÿ
python# çº¿æ€§çº¦æŸ + äºŒæ¬¡ç›®æ ‡ = å‡¸ä¼˜åŒ–é—®é¢˜
# è¿™æ˜¯ä¼˜åŒ–ç†è®ºä¸­çš„ç»å…¸ç»„åˆï¼

minimize    f(x) = x^T Q x        # å‡¸ç›®æ ‡å‡½æ•°ï¼ˆäºŒæ¬¡ï¼‰
subject to  g(x) = Ax - b = 0     # çº¿æ€§çº¦æŸ
            h(x) = Cx - d â‰¤ 0     # çº¿æ€§çº¦æŸ
ç»“æœï¼š

æœ‰å…¨å±€æœ€ä¼˜è§£
å¯ä»¥ç”¨é«˜æ•ˆç®—æ³•æ±‚è§£ï¼ˆå¦‚å†…ç‚¹æ³•ã€æ´»è·ƒé›†æ³•ï¼‰

å…¶ä»–å¸¸è§ç»„åˆ
1. çº¿æ€§åŠ¨åŠ›å­¦ + çº¿æ€§æˆæœ¬
pythonminimize    Î£(|x_k| + |u_k|)           # çº¿æ€§ç›®æ ‡
subject to  x_{k+1} = Ax_k + Bu_k      # çº¿æ€§çº¦æŸ
é—®é¢˜ç±»å‹ï¼šçº¿æ€§è§„åˆ’ï¼ˆLPï¼‰
2. çº¿æ€§åŠ¨åŠ›å­¦ + äºŒæ¬¡æˆæœ¬ï¼ˆæˆ‘ä»¬çš„æƒ…å†µï¼‰
pythonminimize    Î£(x_k^T Q x_k + u_k^T R u_k)  # äºŒæ¬¡ç›®æ ‡
subject to  x_{k+1} = Ax_k + Bu_k          # çº¿æ€§çº¦æŸ
é—®é¢˜ç±»å‹ï¼šäºŒæ¬¡è§„åˆ’ï¼ˆQPï¼‰
3. éçº¿æ€§åŠ¨åŠ›å­¦ + äºŒæ¬¡æˆæœ¬
pythonminimize    Î£(x_k^T Q x_k + u_k^T R u_k)     # äºŒæ¬¡ç›®æ ‡
subject to  x_{k+1} = f(x_k, u_k)            # éçº¿æ€§çº¦æŸ
é—®é¢˜ç±»å‹ï¼šéçº¿æ€§è§„åˆ’ï¼ˆNLPï¼‰
å®é™…ä»£ç ä¸­çš„ä½“ç°
çº¿æ€§éƒ¨åˆ†
python# åŠ¨åŠ›å­¦çº¦æŸï¼ˆçº¿æ€§ï¼‰
for k in range(K):
    x_tot_next = A @ x_tot[:, k] + B @ u_tot[:, k]  # çº¿æ€§ï¼
    opti.subject_to(x_tot[:, k+1] == x_tot_next)
äºŒæ¬¡éƒ¨åˆ†
python# æˆæœ¬å‡½æ•°ï¼ˆäºŒæ¬¡ï¼‰
for k in range(K):
    cost += x_tot[:,k].T @ Q @ x_tot[:,k]  # äºŒæ¬¡ï¼
    cost += u_tot[:,k].T @ R @ u_tot[:,k]  # äºŒæ¬¡ï¼
ä¸ºä»€ä¹ˆä¸ç”¨çº¿æ€§æˆæœ¬ï¼Ÿ
çº¿æ€§æˆæœ¬çš„é—®é¢˜
python# å‡è®¾ç”¨çº¿æ€§æˆæœ¬
cost = Î£(|x_k| + |u_k|)
ç¼ºç‚¹ï¼š

ä¸å¯å¾®ï¼šåœ¨åŸç‚¹å¤„æ¢¯åº¦ä¸å­˜åœ¨
è§£å¯èƒ½ä¸å”¯ä¸€ï¼šå¯èƒ½æœ‰å¤šä¸ªæœ€ä¼˜è§£
æ§åˆ¶ä¸å¹³æ»‘ï¼šå®¹æ˜“äº§ç”Ÿçªå˜

äºŒæ¬¡æˆæœ¬çš„ä¼˜åŠ¿
python# ä½¿ç”¨äºŒæ¬¡æˆæœ¬
cost = Î£(x_k^T Q x_k + u_k^T R u_k)
ä¼˜ç‚¹ï¼š

å¤„å¤„å¯å¾®ï¼šæ¢¯åº¦å¤„å¤„å­˜åœ¨
è§£å”¯ä¸€ï¼šæœ‰å”¯ä¸€çš„å…¨å±€æœ€ä¼˜è§£
æ§åˆ¶å¹³æ»‘ï¼šé¼“åŠ±å¹³æ»‘å˜åŒ–

æ€»ç»“
å…³é”®ç†è§£ï¼š

"çº¿æ€§ç³»ç»Ÿ" æŒ‡çš„æ˜¯åŠ¨åŠ›å­¦æ–¹ç¨‹æ˜¯çº¿æ€§çš„
"äºŒæ¬¡æˆæœ¬" æŒ‡çš„æ˜¯ç›®æ ‡å‡½æ•°æ˜¯äºŒæ¬¡çš„
ä¸¤è€…å¯ä»¥å®Œç¾ç»“åˆï¼šçº¿æ€§çº¦æŸ + äºŒæ¬¡ç›®æ ‡ = å‡¸ä¼˜åŒ–é—®é¢˜

æ¯”å–»ï¼š

å°±åƒç‰©ç†å®šå¾‹ï¼ˆåŠ¨åŠ›å­¦ï¼‰æ˜¯çº¿æ€§çš„ï¼Œä½†è¯„ä»·æ ‡å‡†ï¼ˆæˆæœ¬ï¼‰æ˜¯äºŒæ¬¡çš„ã€‚æ¯”å¦‚ç‰›é¡¿ç¬¬äºŒå®šå¾‹ F=maF = ma
F=ma æ˜¯çº¿æ€§çš„ï¼Œä½†èƒ½é‡ E=12mv2E = \frac{1}{2}mv^2
E=21â€‹mv2 æ˜¯äºŒæ¬¡çš„ï¼


è¿™ç§ç»„åˆçš„ç¾å¦™ä¹‹å¤„ï¼šæ—¢ä¿æŒäº†è®¡ç®—çš„é«˜æ•ˆæ€§ï¼ˆçº¿æ€§çº¦æŸï¼‰ï¼Œåˆå®ç°äº†æ§åˆ¶çš„ä¼˜è‰¯æ€§è´¨ï¼ˆäºŒæ¬¡æˆæœ¬ï¼‰ï¼

We now add the control and state constraints,
```python
# constrain the control
opti.subject_to(opti.bounded(-u_max, u_tot, u_max))

# constrain the position only
opti.subject_to(opti.bounded(x_1_min, x_tot[0,:], x_1_max))

```
and solve:
```python
# Say we want to minimise the cost and specify the solver (ipopt)
opts = {"ipopt.print_level": 0, "print_time": 0}
opti.minimize(cost)
opti.solver("ipopt", opts)
    
solution = opti.solve()

# Get solution
x_opt = solution.value(x_tot)
u_opt = solution.value(u_tot)

```

We can plot the solution with the repoâ€™s plot_solution() function.

```python
from MPC_tutorial import plot_solution

plot_solution(x_opt, u_opt.reshape(1,-1)) # must reshape u_opt to (1,K)

```

![alt text](ec822aac-4f77-4739-80cc-c95c6097bd7d.png)


---

### ç°å® vs ç†æƒ³çš„å¯¹æ¯”
ç†æƒ³æƒ…å†µï¼ˆä¸Šé¢çš„ä¾‹å­ï¼‰

```python
# å‡è®¾å®Œç¾ä¼ æ„Ÿå™¨ï¼Œæ— å™ªå£°
x_bar = æ¨¡å‹è®¡ç®—çš„ç²¾ç¡®å€¼  # å®Œç¾é¢„æµ‹
```

ç°å®æƒ…å†µï¼ˆåœè½¦ä¾‹å­ï¼‰
```python
# æœ‰å™ªå£°çš„è§‚æµ‹
GPSè¯»æ•° = çœŸå®ä½ç½® + GPSè¯¯å·®  # Â±0.3mè¯¯å·®
é€Ÿåº¦è¯»æ•° = çœŸå®é€Ÿåº¦ + ä»ªè¡¨è¯¯å·®  # Â±0.05m/sè¯¯å·®

# è§‚æµ‹å€¼æˆä¸ºä¸‹ä¸€æ­¥MPCçš„èµ·ç‚¹
x_bar = [GPSè¯»æ•°, é€Ÿåº¦è¯»æ•°]  # å¸¦å™ªå£°çš„åˆå§‹æ¡ä»¶
```


### ğŸš—ğŸ¯ å®é™…è¿è¡Œç¤ºä¾‹
```python
=== æ—¶é—´æ­¥ 0 ===
ä¼ æ„Ÿå™¨è§‚æµ‹: ä½ç½®=49.73m, é€Ÿåº¦=10.12m/s (æœ‰å™ªå£°)
MPCåˆå§‹çŠ¶æ€: ä½ç½®=49.73m, é€Ÿåº¦=10.12m/s (åŸºäºè§‚æµ‹)
æœ€ä¼˜æ§åˆ¶: -2500N (åˆ¹è½¦)
çœŸå®çŠ¶æ€æ¼”åŒ–: ä½ç½®=50.85m, é€Ÿåº¦=8.33m/s

=== æ—¶é—´æ­¥ 1 ===  
ä¼ æ„Ÿå™¨è§‚æµ‹: ä½ç½®=50.91m, é€Ÿåº¦=8.27m/s (é‡æ–°è§‚æµ‹!)
MPCåˆå§‹çŠ¶æ€: ä½ç½®=50.91m, é€Ÿåº¦=8.27m/s (åŸºäºæ–°è§‚æµ‹)
æœ€ä¼˜æ§åˆ¶: -2200N (ç»§ç»­åˆ¹è½¦)
çœŸå®çŠ¶æ€æ¼”åŒ–: ä½ç½®=51.68m, é€Ÿåº¦=6.87m/s
```
##### å…³é”®ç†è§£ï¼š

`æ¯æ­¥`çš„è§‚æµ‹å€¼ï¼šæˆä¸ºè¯¥æ­¥MPCä¼˜åŒ–çš„èµ·å§‹çŠ¶æ€`x_bar`
æ—¶é—´åŒ¹é…ï¼šè§‚æµ‹å€¼çš„æ—¶é—´æˆ³å¿…é¡»ä¸MPCå¾ªç¯`åŒæ­¥`
å™ªå£°å¤„ç†ï¼šè§‚æµ‹å€¼çš„è´¨é‡ç›´æ¥å½±å“MPCæ€§èƒ½
é—­ç¯åé¦ˆï¼šæ­£æ˜¯å› ä¸ºæœ‰è§‚æµ‹åé¦ˆï¼ŒMPCèƒ½çº æ­£é¢„æµ‹è¯¯å·®

#### å°±æ˜¯MPCä¸­è§‚æµ‹å€¼é©±åŠ¨æ§åˆ¶å¾ªç¯çš„å®Œæ•´è¿‡ç¨‹ï¼ğŸš—ğŸ¯